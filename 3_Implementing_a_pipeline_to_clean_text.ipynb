{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamini2015/NLP-Implementation/blob/main/3_Implementing_a_pipeline_to_clean_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HKWpBm009h4"
      },
      "source": [
        "# NLP Basics: Implementing A Pipeline To Clean Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spn_aTzi09h6"
      },
      "source": [
        "### Pre-processing Text Data\n",
        "\n",
        "Cleaning up the text data is necessary to highlight attributes that you're going to want your machine learning system to pick up on. We will explore three pre-processing steps in this lesson:\n",
        "1. Remove punctuation\n",
        "2. Tokenization\n",
        "3. Remove stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkxaMAOr09h7",
        "outputId": "814b6ba3-e82f-403e-8d55-3be0659ab27d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1   ham   \n",
              "2  spam   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                                  text  \n",
              "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
              "1                                                                        Ok lar... Joking wif u oni...  \n",
              "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
              "3                                                    U dun say so early hor... U c already then say...  \n",
              "4                                        Nah I don't think he goes to usf, he lives around here though  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read in raw data and clean up the column names\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "\n",
        "messages = pd.read_csv('../../../data/spam.csv', encoding='latin-1')\n",
        "messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
        "messages.columns = [\"label\", \"text\"]\n",
        "messages.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppT7AZ1L09h9"
      },
      "source": [
        "### Remove Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tX4K0mrU09h9",
        "outputId": "18db3ac9-e3d6-489e-826d-72e9154f0711"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# What punctuation is included in the default list?\n",
        "import string\n",
        "\n",
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBTK-j7j09h9",
        "outputId": "41b00b91-1b77-412b-f0d2-3e716be74a73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Why is it important to remove punctuation?\n",
        "\n",
        "\"This message is spam\" == \"This message is spam.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnOnXcxk09h-",
        "outputId": "bfb04007-2e38-402b-ab29-d869efbf4d9b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
              "      <td>Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>Ok lar Joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>U dun say so early hor U c already then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1   ham   \n",
              "2  spam   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                                  text  \\\n",
              "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
              "1                                                                        Ok lar... Joking wif u oni...   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "3                                                    U dun say so early hor... U c already then say...   \n",
              "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "\n",
              "                                                                                            text_clean  \n",
              "0  Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amo...  \n",
              "1                                                                              Ok lar Joking wif u oni  \n",
              "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...  \n",
              "3                                                          U dun say so early hor U c already then say  \n",
              "4                                          Nah I dont think he goes to usf he lives around here though  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a function to remove punctuation in our messages\n",
        "def remove_punct(text):\n",
        "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    return text\n",
        "\n",
        "messages['text_clean'] = messages['text'].apply(lambda x: remove_punct(x))\n",
        "\n",
        "messages.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbJlaHc809h-"
      },
      "source": [
        "### Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD98Otht09h-",
        "outputId": "c35e374b-6b35-4e8e-b917-cab8ffb9328c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
              "      <td>Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amo...</td>\n",
              "      <td>[go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, ci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>Ok lar Joking wif u oni</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>U dun say so early hor U c already then say</td>\n",
              "      <td>[u, dun, say, so, early, hor, u, c, already, then, say]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
              "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1   ham   \n",
              "2  spam   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                                  text  \\\n",
              "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
              "1                                                                        Ok lar... Joking wif u oni...   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "3                                                    U dun say so early hor... U c already then say...   \n",
              "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "\n",
              "                                                                                            text_clean  \\\n",
              "0  Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amo...   \n",
              "1                                                                              Ok lar Joking wif u oni   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...   \n",
              "3                                                          U dun say so early hor U c already then say   \n",
              "4                                          Nah I dont think he goes to usf he lives around here though   \n",
              "\n",
              "                                                                                        text_tokenized  \n",
              "0  [go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, ci...  \n",
              "1                                                                       [ok, lar, joking, wif, u, oni]  \n",
              "2  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...  \n",
              "3                                              [u, dun, say, so, early, hor, u, c, already, then, say]  \n",
              "4                            [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a function to split our sentences into a list of words\n",
        "import re\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = re.split('\\W+', text)\n",
        "    return tokens\n",
        "\n",
        "messages['text_tokenized'] = messages['text_clean'].apply(lambda x: tokenize(x.lower()))\n",
        "\n",
        "messages.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bbn7Y9509h-"
      },
      "source": [
        "### Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fip1WJdl09h-",
        "outputId": "94f1b102-b8da-4c0e-a04e-ea4e4fc60494"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i', 'am', 'learning', 'nlp']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# What does an example look like?\n",
        "\n",
        "tokenize(\"I am learning NLP\".lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2SG5HKu09h_"
      },
      "outputs": [],
      "source": [
        "# Load the list of stopwords built into nltk\n",
        "import nltk\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hWStiRU09h_",
        "outputId": "dc5bd7a2-9c4c-493f-8852-146ff93eb1c9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_tokenized</th>\n",
              "      <th>text_nostop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
              "      <td>Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amo...</td>\n",
              "      <td>[go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, ci...</td>\n",
              "      <td>[go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>Ok lar Joking wif u oni</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>U dun say so early hor U c already then say</td>\n",
              "      <td>[u, dun, say, so, early, hor, u, c, already, then, say]</td>\n",
              "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
              "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
              "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1   ham   \n",
              "2  spam   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                                  text  \\\n",
              "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
              "1                                                                        Ok lar... Joking wif u oni...   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "3                                                    U dun say so early hor... U c already then say...   \n",
              "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "\n",
              "                                                                                            text_clean  \\\n",
              "0  Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amo...   \n",
              "1                                                                              Ok lar Joking wif u oni   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...   \n",
              "3                                                          U dun say so early hor U c already then say   \n",
              "4                                          Nah I dont think he goes to usf he lives around here though   \n",
              "\n",
              "                                                                                        text_tokenized  \\\n",
              "0  [go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, ci...   \n",
              "1                                                                       [ok, lar, joking, wif, u, oni]   \n",
              "2  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...   \n",
              "3                                              [u, dun, say, so, early, hor, u, c, already, then, say]   \n",
              "4                            [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]   \n",
              "\n",
              "                                                                                           text_nostop  \n",
              "0  [go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]  \n",
              "1                                                                       [ok, lar, joking, wif, u, oni]  \n",
              "2  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...  \n",
              "3                                                        [u, dun, say, early, hor, u, c, already, say]  \n",
              "4                                                 [nah, dont, think, goes, usf, lives, around, though]  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a function to remove all stopwords\n",
        "def remove_stopwords(tokenized_text):\n",
        "    text = [word for word in tokenized_text if word not in stopwords]\n",
        "    return text\n",
        "\n",
        "messages['text_nostop'] = messages['text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "messages.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipS5RLK309h_",
        "outputId": "3b2d626d-d28c-4e55-ff13-906d4edae454"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['learning', 'nlp']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove stopwords in our example\n",
        "remove_stopwords(tokenize(\"I am learning NLP\".lower()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN1tqKDB09iA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}